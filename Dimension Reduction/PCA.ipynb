{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA (Principal Component Analysis)\n",
    "\n",
    "PCA is a dimensionality reduction technique that can be used to significantly speed up your unsupervised feature learning algorithm. It can also be used to visualize high-dimensional data in 2D or 3D. In this exercise, we will implement PCA and apply it to the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why PCA?\n",
    "\n",
    "The motivation behind the algorithm is that there are certain features that capture a large percentage of variance in the original dataset. So it's important to find the directions of maximum variance in the dataset. These directions are called principal components. And PCA is essentially a projection of the dataset onto the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How PCA works\n",
    "\n",
    "The steps of PCA are as follows:\n",
    "\n",
    "1. Compute the covariance matrix of the data.\n",
    "2. Compute the eigenvectors of the covariance matrix.\n",
    "3. Take the eigenvectors corresponding to the largest eigenvalues and use them to form a projection matrix.\n",
    "4. Project the data into the subspace spanned by the projection matrix.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"pca.png\" width=500 height=350/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "df = datasets.load_wine(as_frame=True)\n",
    "df = pd.DataFrame(df.data, columns=df.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's standarize the data first. This is because PCA is sensitive to the scale of the data.\n",
    "What standardization does is, it makes the mean of all the features equal to zero and the variance equal to one.\n",
    "This makes sure that all the features are on a similar scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.518613</td>\n",
       "      <td>-0.562250</td>\n",
       "      <td>0.232053</td>\n",
       "      <td>-1.169593</td>\n",
       "      <td>1.913905</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>1.034819</td>\n",
       "      <td>-0.659563</td>\n",
       "      <td>1.224884</td>\n",
       "      <td>0.251717</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>1.847920</td>\n",
       "      <td>1.013009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246290</td>\n",
       "      <td>-0.499413</td>\n",
       "      <td>-0.827996</td>\n",
       "      <td>-2.490847</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.568648</td>\n",
       "      <td>0.733629</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>-0.544721</td>\n",
       "      <td>-0.293321</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>1.113449</td>\n",
       "      <td>0.965242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196879</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>1.109334</td>\n",
       "      <td>-0.268738</td>\n",
       "      <td>0.088358</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>1.215533</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>2.135968</td>\n",
       "      <td>0.269020</td>\n",
       "      <td>0.318304</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>1.395148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.691550</td>\n",
       "      <td>-0.346811</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>-0.809251</td>\n",
       "      <td>0.930918</td>\n",
       "      <td>2.491446</td>\n",
       "      <td>1.466525</td>\n",
       "      <td>-0.981875</td>\n",
       "      <td>1.032155</td>\n",
       "      <td>1.186068</td>\n",
       "      <td>-0.427544</td>\n",
       "      <td>1.184071</td>\n",
       "      <td>2.334574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.227694</td>\n",
       "      <td>1.840403</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>1.281985</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>0.663351</td>\n",
       "      <td>0.226796</td>\n",
       "      <td>0.401404</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>0.449601</td>\n",
       "      <td>-0.037874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.876275</td>\n",
       "      <td>2.974543</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>0.301803</td>\n",
       "      <td>-0.332922</td>\n",
       "      <td>-0.985614</td>\n",
       "      <td>-1.424900</td>\n",
       "      <td>1.274310</td>\n",
       "      <td>-0.930179</td>\n",
       "      <td>1.142811</td>\n",
       "      <td>-1.392758</td>\n",
       "      <td>-1.231206</td>\n",
       "      <td>-0.021952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.493343</td>\n",
       "      <td>1.412609</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>1.052516</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>-0.793334</td>\n",
       "      <td>-1.284344</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>-0.316950</td>\n",
       "      <td>0.969783</td>\n",
       "      <td>-1.129518</td>\n",
       "      <td>-1.485445</td>\n",
       "      <td>0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.332758</td>\n",
       "      <td>1.744744</td>\n",
       "      <td>-0.389355</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>1.422412</td>\n",
       "      <td>-1.129824</td>\n",
       "      <td>-1.344582</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>-0.422075</td>\n",
       "      <td>2.224236</td>\n",
       "      <td>-1.612125</td>\n",
       "      <td>-1.485445</td>\n",
       "      <td>0.280575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.209232</td>\n",
       "      <td>0.227694</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>1.422412</td>\n",
       "      <td>-1.033684</td>\n",
       "      <td>-1.354622</td>\n",
       "      <td>1.354888</td>\n",
       "      <td>-0.229346</td>\n",
       "      <td>1.834923</td>\n",
       "      <td>-1.568252</td>\n",
       "      <td>-1.400699</td>\n",
       "      <td>0.296498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.395086</td>\n",
       "      <td>1.583165</td>\n",
       "      <td>1.365208</td>\n",
       "      <td>1.502943</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>-0.392751</td>\n",
       "      <td>-1.274305</td>\n",
       "      <td>1.596623</td>\n",
       "      <td>-0.422075</td>\n",
       "      <td>1.791666</td>\n",
       "      <td>-1.524378</td>\n",
       "      <td>-1.428948</td>\n",
       "      <td>-0.595160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "0    1.518613   -0.562250  0.232053          -1.169593   1.913905   \n",
       "1    0.246290   -0.499413 -0.827996          -2.490847   0.018145   \n",
       "2    0.196879    0.021231  1.109334          -0.268738   0.088358   \n",
       "3    1.691550   -0.346811  0.487926          -0.809251   0.930918   \n",
       "4    0.295700    0.227694  1.840403           0.451946   1.281985   \n",
       "..        ...         ...       ...                ...        ...   \n",
       "173  0.876275    2.974543  0.305159           0.301803  -0.332922   \n",
       "174  0.493343    1.412609  0.414820           1.052516   0.158572   \n",
       "175  0.332758    1.744744 -0.389355           0.151661   1.422412   \n",
       "176  0.209232    0.227694  0.012732           0.151661   1.422412   \n",
       "177  1.395086    1.583165  1.365208           1.502943  -0.262708   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0         0.808997    1.034819             -0.659563         1.224884   \n",
       "1         0.568648    0.733629             -0.820719        -0.544721   \n",
       "2         0.808997    1.215533             -0.498407         2.135968   \n",
       "3         2.491446    1.466525             -0.981875         1.032155   \n",
       "4         0.808997    0.663351              0.226796         0.401404   \n",
       "..             ...         ...                   ...              ...   \n",
       "173      -0.985614   -1.424900              1.274310        -0.930179   \n",
       "174      -0.793334   -1.284344              0.549108        -0.316950   \n",
       "175      -1.129824   -1.344582              0.549108        -0.422075   \n",
       "176      -1.033684   -1.354622              1.354888        -0.229346   \n",
       "177      -0.392751   -1.274305              1.596623        -0.422075   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  \n",
       "0           0.251717  0.362177                      1.847920  1.013009  \n",
       "1          -0.293321  0.406051                      1.113449  0.965242  \n",
       "2           0.269020  0.318304                      0.788587  1.395148  \n",
       "3           1.186068 -0.427544                      1.184071  2.334574  \n",
       "4          -0.319276  0.362177                      0.449601 -0.037874  \n",
       "..               ...       ...                           ...       ...  \n",
       "173         1.142811 -1.392758                     -1.231206 -0.021952  \n",
       "174         0.969783 -1.129518                     -1.485445  0.009893  \n",
       "175         2.224236 -1.612125                     -1.485445  0.280575  \n",
       "176         1.834923 -1.568252                     -1.400699  0.296498  \n",
       "177         1.791666 -1.524378                     -1.428948 -0.595160  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaled_df = scaler.transform(df) # could also use fit_transform\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform PCA now baby!\n",
    "\n",
    "In sklearn, PCA is implemented as a transformer object that learns n components in its fit method, and can be used on new data to project it on these components.\n",
    "\n",
    "Parmaeters of PCA:\n",
    "\n",
    "- n_components: Number of components to keep. If n_components is not set all components are kept.\n",
    "- whiten: When True (False by default) the components_ vectors are divided by n_samples times singular values to ensure uncorrelated outputs with unit component-wise variances. Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.\n",
    "\n",
    "For more : https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.316751</td>\n",
       "      <td>-1.443463</td>\n",
       "      <td>-0.165739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.209465</td>\n",
       "      <td>0.333393</td>\n",
       "      <td>-2.026457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.516740</td>\n",
       "      <td>-1.031151</td>\n",
       "      <td>0.982819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.757066</td>\n",
       "      <td>-2.756372</td>\n",
       "      <td>-0.176192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.008908</td>\n",
       "      <td>-0.869831</td>\n",
       "      <td>2.026688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-3.370524</td>\n",
       "      <td>-2.216289</td>\n",
       "      <td>-0.342570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-2.601956</td>\n",
       "      <td>-1.757229</td>\n",
       "      <td>0.207581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-2.677839</td>\n",
       "      <td>-2.760899</td>\n",
       "      <td>-0.940942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-2.387017</td>\n",
       "      <td>-2.297347</td>\n",
       "      <td>-0.550696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-3.208758</td>\n",
       "      <td>-2.768920</td>\n",
       "      <td>1.013914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PC1       PC2       PC3\n",
       "0    3.316751 -1.443463 -0.165739\n",
       "1    2.209465  0.333393 -2.026457\n",
       "2    2.516740 -1.031151  0.982819\n",
       "3    3.757066 -2.756372 -0.176192\n",
       "4    1.008908 -0.869831  2.026688\n",
       "..        ...       ...       ...\n",
       "173 -3.370524 -2.216289 -0.342570\n",
       "174 -2.601956 -1.757229  0.207581\n",
       "175 -2.677839 -2.760899 -0.940942\n",
       "176 -2.387017 -2.297347 -0.550696\n",
       "177 -3.208758 -2.768920  1.013914\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "new_data = pca.fit_transform(scaled_df)   # new data with 3 principal components\n",
    "new_data = pd.DataFrame(new_data, columns=['PC1', 'PC2', 'PC3'])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36198848 0.1920749  0.11123631]\n",
      "[28.94203422 21.08225141 16.04371561]\n",
      "[4.73243698 2.51108093 1.45424187]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)    # it is a list of the variance explained by each of the principal components\n",
    "print(pca.singular_values_)             # it is a list of the singular values\n",
    "print(pca.explained_variance_)          # it is a list of the variance explained by each of the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1443294  -0.24518758 -0.00205106 -0.23932041  0.14199204  0.39466085\n",
      "   0.4229343  -0.2985331   0.31342949 -0.0886167   0.29671456  0.37616741\n",
      "   0.28675223]\n",
      " [-0.48365155 -0.22493093 -0.31606881  0.0105905  -0.299634   -0.06503951\n",
      "   0.00335981 -0.02877949 -0.03930172 -0.52999567  0.27923515  0.16449619\n",
      "  -0.36490283]\n",
      " [-0.20738262  0.08901289  0.6262239   0.61208035  0.13075693  0.14617896\n",
      "   0.1506819   0.17036816  0.14945431 -0.13730621  0.08522192  0.16600459\n",
      "  -0.12674592]]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_)  # it is a list of the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05579312  0.05482031  0.18366728 -0.28802092  0.36093877  0.27904562\n",
      "   0.22702748 -0.19211219  0.20219036  0.50552844 -0.1140751   0.03321036\n",
      "   0.57041942]\n",
      " [ 0.05482031  0.80872556  0.20624483  0.30246803  0.00205704 -0.37203396\n",
      "  -0.43330102  0.34321028 -0.29820104  0.32808029 -0.43497691 -0.4578201\n",
      "  -0.14324449]\n",
      " [ 0.18366728  0.20624483  1.04342443  0.38485763  0.27836946  0.13221557\n",
      "   0.09000633  0.12995853  0.1181486   0.26070718 -0.131359   -0.00543064\n",
      "   0.1559266 ]\n",
      " [-0.28802092  0.30246803  0.38485763  1.06467545 -0.07115812 -0.31611516\n",
      "  -0.34087189  0.41223283 -0.23001815 -0.0059975  -0.2458137  -0.27972899\n",
      "  -0.38162344]\n",
      " [ 0.36093877  0.00205704  0.27836946 -0.07115812  0.72770416  0.30052015\n",
      "   0.27586481 -0.14152778  0.23542691  0.2569887   0.01878937  0.14926839\n",
      "   0.38473515]\n",
      " [ 0.27904562 -0.37203396  0.13221557 -0.31611516  0.30052015  1.13702106\n",
      "   0.73882122 -0.47681781  0.55877969 -0.09913736  0.47794369  0.6400969\n",
      "   0.51642409]\n",
      " [ 0.22702748 -0.43330102  0.09000633 -0.34087189  0.27586481  0.73882122\n",
      "   1.22891345 -0.51637067  0.59194983 -0.18569435  0.55396714  0.70986514\n",
      "   0.49891137]\n",
      " [-0.19211219  0.34321028  0.12995853  0.41223283 -0.14152778 -0.47681781\n",
      "  -0.51637067  0.85156263 -0.37363476  0.12146548 -0.38233772 -0.46336975\n",
      "  -0.3678404 ]\n",
      " [ 0.20219036 -0.29820104  0.1181486  -0.23001815  0.23542691  0.55877969\n",
      "   0.59194983 -0.37363476  0.88539993 -0.09696278  0.38961241  0.51819193\n",
      "   0.3964865 ]\n",
      " [ 0.50552844  0.32808029  0.26070718 -0.0059975   0.2569887  -0.09913736\n",
      "  -0.18569435  0.12146548 -0.09696278  1.07290334 -0.43169147 -0.34711523\n",
      "   0.309567  ]\n",
      " [-0.1140751  -0.43497691 -0.131359   -0.2458137   0.01878937  0.47794369\n",
      "   0.55396714 -0.38233772  0.38961241 -0.43169147  0.98474718  0.58899493\n",
      "   0.14316324]\n",
      " [ 0.03321036 -0.4578201  -0.00543064 -0.27972899  0.14926839  0.6400969\n",
      "   0.70986514 -0.46336975  0.51819193 -0.34711523  0.58899493  1.12942493\n",
      "   0.31741983]\n",
      " [ 0.57041942 -0.14324449  0.1559266  -0.38162344  0.38473515  0.51642409\n",
      "   0.49891137 -0.3678404   0.3964865   0.309567    0.14316324  0.31741983\n",
      "   1.08315109]]\n"
     ]
    }
   ],
   "source": [
    "print(pca.get_covariance()) # it is the covariance matrix of the original data projected onto the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.73200446, -0.10240719, -0.08037323,  0.28411099, -0.27265867,\n",
       "        -0.12906772, -0.0736106 ,  0.11954683, -0.08017507, -0.50269942,\n",
       "         0.19427729,  0.09253647, -0.46088392],\n",
       "       [-0.10240719,  2.05253422, -0.224265  , -0.20425464, -0.07357472,\n",
       "         0.15230063,  0.19507175, -0.18825861,  0.12145114, -0.25050529,\n",
       "         0.25729595,  0.23750805,  0.00895679],\n",
       "       [-0.08037323, -0.224265  ,  1.47027152, -0.60710327, -0.30894132,\n",
       "        -0.18337037, -0.14695793, -0.18889347, -0.17164143, -0.17911984,\n",
       "         0.08254812, -0.06637621, -0.08961758],\n",
       "       [ 0.28411099, -0.20425464, -0.60710327,  1.5677838 , -0.05140309,\n",
       "         0.05424197,  0.06250529, -0.31421315,  0.01020438,  0.10088191,\n",
       "         0.05835625,  0.0210871 ,  0.27357411],\n",
       "       [-0.27265867, -0.07357472, -0.30894132, -0.05140309,  2.04679584,\n",
       "        -0.18354179, -0.1541329 ,  0.03605232, -0.14575023, -0.24490132,\n",
       "         0.05270646, -0.05244737, -0.264302  ],\n",
       "       [-0.12906772,  0.15230063, -0.18337037,  0.05424197, -0.18354179,\n",
       "         1.92018462, -0.38097066,  0.20104081, -0.29628544,  0.03955464,\n",
       "        -0.22850553, -0.32649101, -0.24990524],\n",
       "       [-0.0736106 ,  0.19507175, -0.14695793,  0.06250529, -0.1541329 ,\n",
       "        -0.38097066,  1.87806618,  0.22103604, -0.31066736,  0.11414967,\n",
       "        -0.28256119, -0.37097676, -0.21870782],\n",
       "       [ 0.11954683, -0.18825861, -0.18889347, -0.31421315,  0.03605232,\n",
       "         0.20104081,  0.22103604,  2.0525752 ,  0.15125092, -0.04627859,\n",
       "         0.17568537,  0.19665985,  0.19223109],\n",
       "       [-0.08017507,  0.12145114, -0.17164143,  0.01020438, -0.14575023,\n",
       "        -0.29628544, -0.31066736,  0.15125092,  2.04300289,  0.05108529,\n",
       "        -0.19252424, -0.27197352, -0.18320716],\n",
       "       [-0.50269942, -0.25050529, -0.17911984,  0.10088191, -0.24490132,\n",
       "         0.03955464,  0.11414967, -0.04627859,  0.05108529,  1.70886309,\n",
       "         0.35251183,  0.27007867, -0.34006462],\n",
       "       [ 0.19427729,  0.25729595,  0.08254812,  0.05835625,  0.05270646,\n",
       "        -0.22850553, -0.28256119,  0.17568537, -0.19252424,  0.35251183,\n",
       "         1.94401052, -0.34077807,  0.03307605],\n",
       "       [ 0.09253647,  0.23750805, -0.06637621,  0.0210871 , -0.05244737,\n",
       "        -0.32649101, -0.37097676,  0.19665985, -0.27197352,  0.27007867,\n",
       "        -0.34077807,  1.89678129, -0.07682984],\n",
       "       [-0.46088392,  0.00895679, -0.08961758,  0.27357411, -0.264302  ,\n",
       "        -0.24990524, -0.21870782,  0.19223109, -0.18320716, -0.34006462,\n",
       "         0.03307605, -0.07682984,  1.83786892]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.get_precision() # it is the precision matrix (inverse covariance matrix) of the original data projected onto the principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained variance is a concept associated with dimensionality reduction techniques, particularly Principal Component Analysis (PCA). In the context of PCA, each principal component corresponds to an eigenvalue, which represents the variance of the data along that component. The total explained variance is the sum of all these eigenvalues.\n",
    "\n",
    "Here's a breakdown of the terms:\n",
    "\n",
    "### Eigenvalue: \n",
    "In PCA, eigenvalues represent the amount of variance captured by each principal component. Larger eigenvalues indicate that the corresponding principal components explain more variance in the data.\n",
    "\n",
    "### Explained Variance: <br>\n",
    "The explained variance is the proportion of the total variance in the dataset that is \"explained\" or captured by a subset of the principal components. It is the ratio of the sum of the eigenvalues of the selected principal components to the total sum of eigenvalues.\n",
    "\n",
    "$$ \n",
    "ExplainedVariance = \\frac{\\sum_{i=1}^{k}{Eigenvalue_i}}{\\sum_{i=1}^{n}{Eigenvalue_i}}\n",
    "$$​\n",
    "\n",
    "Here, \n",
    "k is the number of selected principal components, and \n",
    "n is the total number of principal components.\n",
    "Interpretation:\n",
    "\n",
    "A higher explained variance indicates that the selected principal components retain more information about the original data. It is often used to assess how well the reduced-dimensional representation (lower-dimensional space) preserves the variability present in the original data.\n",
    "\n",
    "For example, if 90% of the total variance is explained by a certain number of principal components, it implies that using only those components retains most of the information in the data.\n",
    "\n",
    "### Application:\n",
    "\n",
    "Explained variance is frequently used in the context of selecting the number of principal components to retain. One common approach is to choose a number of components that collectively explain a sufficiently high percentage of the total variance, e.g., 90% or 95%.\n",
    "In scikit-learn's PCA implementation, you can access the explained variance of each component using the attribute explained_variance_. The cumulative explained variance is often visualized using a scree plot to help determine the appropriate number of components to retain for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
