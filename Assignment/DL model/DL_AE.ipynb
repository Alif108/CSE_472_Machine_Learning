{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([329, 64])\n",
      "torch.Size([83, 64])\n",
      "(329,)\n",
      "(83,)\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open('../Data/train_enc.pkl', 'rb'))\n",
    "X_test = pickle.load(open('../Data/test_enc.pkl', 'rb'))\n",
    "y_train = pickle.load(open('../Data/y_train.pkl', 'rb'))\n",
    "y_test = pickle.load(open('../Data/y_test.pkl', 'rb'))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([329, 64]),\n",
       " torch.Size([83, 64]),\n",
       " torch.Size([329]),\n",
       " torch.Size([83]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class DLModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DLModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def fit(self, X, y, epochs, batch_size, lr):\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "        # for epoch in tqdm(range(epochs)):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "\n",
    "                y_pred = self(X_batch)\n",
    "                loss = criterion(y_pred, y_batch.view(-1, 1))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print('Epoch: {}, Loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "input_size = 64\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.3660063147544861\n",
      "Epoch: 1, Loss: 0.05415228754281998\n",
      "Epoch: 2, Loss: 0.05194460228085518\n",
      "Epoch: 3, Loss: 0.04227403178811073\n",
      "Epoch: 4, Loss: 0.027695754542946815\n",
      "Epoch: 5, Loss: 0.014798389747738838\n",
      "Epoch: 6, Loss: 0.017971064895391464\n",
      "Epoch: 7, Loss: 0.0006824922165833414\n",
      "Epoch: 8, Loss: 0.03133947402238846\n",
      "Epoch: 9, Loss: 0.3476465344429016\n",
      "Epoch: 10, Loss: 0.007393086329102516\n",
      "Epoch: 11, Loss: 0.0017734612338244915\n",
      "Epoch: 12, Loss: 0.0008918307721614838\n",
      "Epoch: 13, Loss: 0.0006353975040838122\n",
      "Epoch: 14, Loss: 0.0002646992215886712\n",
      "Epoch: 15, Loss: 0.0001481388317188248\n",
      "Epoch: 16, Loss: 9.428561315871775e-05\n",
      "Epoch: 17, Loss: 6.432150985347107e-05\n",
      "Epoch: 18, Loss: 4.5572000090032816e-05\n",
      "Epoch: 19, Loss: 3.367421595612541e-05\n",
      "Epoch: 20, Loss: 2.634788143041078e-05\n",
      "Epoch: 21, Loss: 2.1035528334323317e-05\n",
      "Epoch: 22, Loss: 1.694872662483249e-05\n",
      "Epoch: 23, Loss: 1.266994331672322e-05\n",
      "Epoch: 24, Loss: 9.94775564322481e-06\n",
      "Epoch: 25, Loss: 8.285327567136846e-06\n",
      "Epoch: 26, Loss: 7.225623448903207e-06\n",
      "Epoch: 27, Loss: 6.463966656156117e-06\n",
      "Epoch: 28, Loss: 5.848021373822121e-06\n",
      "Epoch: 29, Loss: 5.285062798066065e-06\n",
      "Epoch: 30, Loss: 4.841320787818404e-06\n",
      "Epoch: 31, Loss: 4.463810000743251e-06\n",
      "Epoch: 32, Loss: 4.139284556003986e-06\n",
      "Epoch: 33, Loss: 3.874366029776866e-06\n",
      "Epoch: 34, Loss: 3.5763337109528948e-06\n",
      "Epoch: 35, Loss: 3.2849247872945853e-06\n",
      "Epoch: 36, Loss: 3.0597452678193804e-06\n",
      "Epoch: 37, Loss: 2.861058419512119e-06\n",
      "Epoch: 38, Loss: 2.708731472012005e-06\n",
      "Epoch: 39, Loss: 2.52329073191504e-06\n",
      "Epoch: 40, Loss: 2.364341753491317e-06\n",
      "Epoch: 41, Loss: 2.2318845367408358e-06\n",
      "Epoch: 42, Loss: 2.1259186269162456e-06\n",
      "Epoch: 43, Loss: 1.980215756702819e-06\n",
      "Epoch: 44, Loss: 1.8477587673260132e-06\n",
      "Epoch: 45, Loss: 1.7616619061300298e-06\n",
      "Epoch: 46, Loss: 1.6821878716655192e-06\n",
      "Epoch: 47, Loss: 1.5563540500806994e-06\n",
      "Epoch: 48, Loss: 1.4835029560344992e-06\n",
      "Epoch: 49, Loss: 1.4238976291380823e-06\n",
      "Epoch: 50, Loss: 1.3378008816289366e-06\n",
      "Epoch: 51, Loss: 1.2781956684193574e-06\n",
      "Epoch: 52, Loss: 1.2252131682544132e-06\n",
      "Epoch: 53, Loss: 1.1523621878950507e-06\n",
      "Epoch: 54, Loss: 1.0861342616408365e-06\n",
      "Epoch: 55, Loss: 1.0463974149388378e-06\n",
      "Epoch: 56, Loss: 1.000037855192204e-06\n",
      "Epoch: 57, Loss: 9.404326988260436e-07\n",
      "Epoch: 58, Loss: 9.006959658108826e-07\n",
      "Epoch: 59, Loss: 8.675820595271944e-07\n",
      "Epoch: 60, Loss: 8.145996730490879e-07\n",
      "Epoch: 61, Loss: 7.814858236088185e-07\n",
      "Epoch: 62, Loss: 7.483719173251302e-07\n",
      "Epoch: 63, Loss: 7.08635241153388e-07\n",
      "Epoch: 64, Loss: 6.755213348696998e-07\n",
      "Epoch: 65, Loss: 6.490301984740654e-07\n",
      "Epoch: 66, Loss: 6.357846586979576e-07\n",
      "Epoch: 67, Loss: 6.026708092576882e-07\n",
      "Epoch: 68, Loss: 5.761796728620538e-07\n",
      "Epoch: 69, Loss: 5.62934189929365e-07\n",
      "Epoch: 70, Loss: 5.430658802652033e-07\n",
      "Epoch: 71, Loss: 5.165747438695689e-07\n",
      "Epoch: 72, Loss: 4.967064342054073e-07\n",
      "Epoch: 73, Loss: 4.834608944292995e-07\n",
      "Epoch: 74, Loss: 4.702153830749012e-07\n",
      "Epoch: 75, Loss: 4.5034710183244897e-07\n",
      "Epoch: 76, Loss: 4.3047879216828733e-07\n",
      "Epoch: 77, Loss: 4.238560507019429e-07\n",
      "Epoch: 78, Loss: 4.106105109258351e-07\n",
      "Epoch: 79, Loss: 3.907422296833829e-07\n",
      "Epoch: 80, Loss: 3.7749671832898457e-07\n",
      "Epoch: 81, Loss: 3.6425120697458624e-07\n",
      "Epoch: 82, Loss: 3.5762843708653236e-07\n",
      "Epoch: 83, Loss: 3.510056956201879e-07\n",
      "Epoch: 84, Loss: 3.311374143777357e-07\n",
      "Epoch: 85, Loss: 3.1789190302333736e-07\n",
      "Epoch: 86, Loss: 3.1789190302333736e-07\n",
      "Epoch: 87, Loss: 2.9802362178088515e-07\n",
      "Epoch: 88, Loss: 2.9140085189283127e-07\n",
      "Epoch: 89, Loss: 2.847781104264868e-07\n",
      "Epoch: 90, Loss: 2.7815536896014237e-07\n",
      "Epoch: 91, Loss: 2.6490985760574404e-07\n",
      "Epoch: 92, Loss: 2.5828708771769016e-07\n",
      "Epoch: 93, Loss: 2.516643462513457e-07\n",
      "Epoch: 94, Loss: 2.4504160478500125e-07\n",
      "Epoch: 95, Loss: 2.384188348969474e-07\n",
      "Epoch: 96, Loss: 2.2517332354254904e-07\n",
      "Epoch: 97, Loss: 2.2517332354254904e-07\n",
      "Epoch: 98, Loss: 2.185505962870593e-07\n",
      "Epoch: 99, Loss: 2.1192782639900543e-07\n"
     ]
    }
   ],
   "source": [
    "model = DLModel(input_size)\n",
    "model.to(device)\n",
    "model.fit(X_train, y_train, epochs, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "with torch.no_grad():\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_pred = y_pred.round()\n",
    "    acc = y_pred.eq(y_train.view_as(y_pred)).sum() / float(len(y_train))\n",
    "    print(f'Train accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8916\n",
      "Test AUC: 0.8615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# test accuracy\n",
    "with torch.no_grad():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    acc = y_pred.eq(y_test.view_as(y_pred)).sum() / float(len(y_test))\n",
    "    print(f'Test accuracy: {acc:.4f}')\n",
    "\n",
    "# test auc\n",
    "with torch.no_grad():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f'Test AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.75      0.71        16\n",
      "         1.0       0.94      0.91      0.92        67\n",
      "\n",
      "    accuracy                           0.88        83\n",
      "   macro avg       0.80      0.83      0.82        83\n",
      "weighted avg       0.89      0.88      0.88        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_ae_dict = {\n",
    "    # 'model': model,\n",
    "    'input_size': input_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'test_accuracy': acc,\n",
    "    'test_auc': auc\n",
    "}\n",
    "\n",
    "pickle.dump(dl_ae_dict, open('dl_ae_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
