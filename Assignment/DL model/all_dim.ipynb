{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329, 20530)\n",
      "(329,)\n",
      "(83, 20530)\n",
      "(83,)\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open('../Data/X_train.pkl', 'rb'))\n",
    "y_train = pickle.load(open('../Data/y_train.pkl', 'rb'))\n",
    "X_test = pickle.load(open('../Data/X_test.pkl', 'rb'))\n",
    "y_test = pickle.load(open('../Data/y_test.pkl', 'rb'))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48855657  0.12112708 -0.33372349 ...  0.04735987  0.50779996\n",
      "  -0.02217494]\n",
      " [ 0.83092164  1.17948768 -0.33372349 ...  0.18754437  0.77965228\n",
      "  -0.17205193]\n",
      " [-1.861054   -0.69352094 -0.33372349 ... -0.35346398 -2.00005787\n",
      "   3.63814136]\n",
      " ...\n",
      " [ 1.50287947  0.88173571  0.1048791  ... -0.33180584  0.91213697\n",
      "  -0.14253948]\n",
      " [-0.06583194  0.60359346 -0.33372349 ...  0.20030191  0.44110666\n",
      "  -1.31512921]\n",
      " [-0.87784052 -0.01478846 -0.33372349 ...  0.12805867  1.46177518\n",
      "  -0.6430939 ]]\n"
     ]
    }
   ],
   "source": [
    "# standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([329, 20530]),\n",
       " torch.Size([83, 20530]),\n",
       " torch.Size([329]),\n",
       " torch.Size([83]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DLModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "input_size = 20530\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:46<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=20530, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Test accuracy: 0.9157\n",
      "Test AUC: 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Instantiate the model\n",
    "model = DLModel(input_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch.view(-1, 1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "print(model.eval())\n",
    "# test accuracy\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    acc = y_pred.eq(y_test.view_as(y_pred)).sum() / float(len(y_test))\n",
    "    print(f'Test accuracy: {acc:.4f}')\n",
    "\n",
    "# test auc\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f'Test AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = {\n",
    "    'model': model,\n",
    "    'input_size': input_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'n_splits': n_splits,\n",
    "    'acc': acc,\n",
    "    'auc': auc\n",
    "}\n",
    "\n",
    "pickle.dump(model_1, open('DL_model_1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a little deeper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DLModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:21<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9277\n",
      "Test AUC: 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Instantiate the model\n",
    "model = DLModel(input_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch.view(-1, 1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# test accuracy\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    acc = y_pred.eq(y_test.view_as(y_pred)).sum() / float(len(y_test))\n",
    "    print(f'Test accuracy: {acc:.4f}')\n",
    "\n",
    "# test auc\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f'Test AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = {\n",
    "    'model': model,\n",
    "    'input_size': input_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'n_splits': n_splits,\n",
    "    'acc': acc,\n",
    "    'auc': auc\n",
    "}\n",
    "\n",
    "pickle.dump(model_1, open('DL_model_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': DLModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=20530, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      "), 'input_size': 20530, 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'n_splits': 5, 'acc': tensor(0.9277), 'auc': 0.9314365671641791}\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('DL_model_2.pkl', 'rb'))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a more deeper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DLModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:36<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9036\n",
      "Test AUC: 0.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Instantiate the model\n",
    "model = DLModel(input_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch.view(-1, 1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# test accuracy\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    acc = y_pred.eq(y_test.view_as(y_pred)).sum() / float(len(y_test))\n",
    "    print(f'Test accuracy: {acc:.4f}')\n",
    "\n",
    "# test auc\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f'Test AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = {\n",
    "    'model': model,\n",
    "    'input_size': input_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'n_splits': n_splits,\n",
    "    'acc': acc,\n",
    "    'auc': auc\n",
    "}\n",
    "\n",
    "pickle.dump(model_1, open('DL_model_3.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedNN(nn.Module):\n",
    "    def __init__(self, input_size, l2_penalty=1e-4):\n",
    "        super(RegularizedNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024, bias=True)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024, 256, bias=True)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, 64, bias=True)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(64, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Apply L2 regularization to the weight parameters of linear layers\n",
    "        self.fc1.weight.data = nn.Parameter(self.fc1.weight.data, requires_grad=True)\n",
    "        self.fc2.weight.data = nn.Parameter(self.fc2.weight.data, requires_grad=True)\n",
    "        self.fc3.weight.data = nn.Parameter(self.fc3.weight.data, requires_grad=True)\n",
    "        self.fc4.weight.data = nn.Parameter(self.fc4.weight.data, requires_grad=True)\n",
    "        \n",
    "        # Set the weight decay for L2 regularization\n",
    "        self.l2_penalty = l2_penalty\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9157\n",
      "Test AUC: 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RegularizedNN(input_size).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch.view(-1, 1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# test accuracy\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    acc = y_pred.eq(y_test.view_as(y_pred)).sum() / float(len(y_test))\n",
    "    print(f'Test accuracy: {acc:.4f}')\n",
    "\n",
    "# test auc\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f'Test AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = {\n",
    "    'model': model,\n",
    "    'input_size': input_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'acc': acc,\n",
    "    'auc': auc\n",
    "}\n",
    "\n",
    "pickle.dump(model_4, open('DL_model_4.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhausive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class DLModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DLModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def fit(self, X, y, epochs, batch_size, lr):\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "        # for epoch in range(epochs):\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "\n",
    "                y_pred = self(X_batch)\n",
    "                loss = criterion(y_pred, y_batch.view(-1, 1))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # print('Epoch: {}, Loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.001, Batch Size: 16, Accuracy: 0.9036144578313253, AUC: 0.8451492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.001, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.8763992537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.001, Batch Size: 64, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.001, Batch Size: 128, Accuracy: 0.9036144578313253, AUC: 0.8927238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.01, Batch Size: 16, Accuracy: 0.9036144578313253, AUC: 0.8927238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.01, Batch Size: 32, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.01, Batch Size: 64, Accuracy: 0.9036144578313253, AUC: 0.8927238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.01, Batch Size: 128, Accuracy: 0.9156626506024096, AUC: 0.8526119402985075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.1, Batch Size: 16, Accuracy: 0.9397590361445783, AUC: 0.9388992537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.1, Batch Size: 32, Accuracy: 0.9036144578313253, AUC: 0.8451492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.1, Batch Size: 64, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, LR: 0.1, Batch Size: 128, Accuracy: 0.9036144578313253, AUC: 0.8451492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy: 0.9156626506024096, AUC: 0.8763992537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy: 0.891566265060241, AUC: 0.8376865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy: 0.927710843373494, AUC: 0.9076492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy: 0.891566265060241, AUC: 0.8614738805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy: 0.9156626506024096, AUC: 0.8763992537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy: 0.927710843373494, AUC: 0.9552238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.8763992537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy: 0.891566265060241, AUC: 0.8614738805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy: 0.8795180722891566, AUC: 0.8302238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.001, Batch Size: 16, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:14<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.001, Batch Size: 32, Accuracy: 0.9036144578313253, AUC: 0.8689365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:08<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.001, Batch Size: 64, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.001, Batch Size: 128, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.01, Batch Size: 16, Accuracy: 0.927710843373494, AUC: 0.9076492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.01, Batch Size: 32, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:08<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.01, Batch Size: 64, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.01, Batch Size: 128, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:28<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.1, Batch Size: 16, Accuracy: 0.9036144578313253, AUC: 0.8927238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.1, Batch Size: 32, Accuracy: 0.927710843373494, AUC: 0.9076492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.1, Batch Size: 64, Accuracy: 0.9036144578313253, AUC: 0.8689365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20, LR: 0.1, Batch Size: 128, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:43<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.001, Batch Size: 16, Accuracy: 0.927710843373494, AUC: 0.9076492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:23<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.001, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.001, Batch Size: 64, Accuracy: 0.9036144578313253, AUC: 0.8927238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:06<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.001, Batch Size: 128, Accuracy: 0.8674698795180723, AUC: 0.7989738805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:42<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.01, Batch Size: 16, Accuracy: 0.927710843373494, AUC: 0.9076492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.01, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.01, Batch Size: 64, Accuracy: 0.891566265060241, AUC: 0.8376865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:06<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.01, Batch Size: 128, Accuracy: 0.9036144578313253, AUC: 0.8689365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:43<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.1, Batch Size: 16, Accuracy: 0.927710843373494, AUC: 0.9076492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.1, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.1, Batch Size: 64, Accuracy: 0.9036144578313253, AUC: 0.8451492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 30, LR: 0.1, Batch Size: 128, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:16<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy: 0.927710843373494, AUC: 0.9076492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.9239738805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:20<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy: 0.9156626506024096, AUC: 0.8763992537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:12<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:21<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy: 0.9036144578313253, AUC: 0.8689365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy: 0.927710843373494, AUC: 0.9314365671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:15<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy: 0.9036144578313253, AUC: 0.8451492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:37<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:21<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy: 0.9156626506024096, AUC: 0.9239738805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy: 0.9156626506024096, AUC: 0.9001865671641791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "epochs_grid = [5, 10, 20, 30, 50]\n",
    "lr_grid = [0.001, 0.01, 0.1]\n",
    "batch_size_grid = [16, 32, 64, 128]\n",
    "\n",
    "# convert to df\n",
    "df = pd.DataFrame(list(itertools.product(epochs_grid, lr_grid, batch_size_grid)), columns=['epochs', 'lr', 'batch_size'])\n",
    "df['acc'] = np.nan\n",
    "df['auc'] = np.nan\n",
    "\n",
    "for epochs, lr, batch_size in itertools.product(epochs_grid, lr_grid, batch_size_grid):\n",
    "    model = DLModel(input_size=X_train.shape[1])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    df.loc[(df['epochs'] == epochs) & (df['lr'] == lr) & (df['batch_size'] == batch_size), 'acc'] = acc\n",
    "    df.loc[(df['epochs'] == epochs) & (df['lr'] == lr) & (df['batch_size'] == batch_size), 'auc'] = auc\n",
    "\n",
    "    print('Epochs: {}, LR: {}, Batch Size: {}, Accuracy: {}, AUC: {}'.format(epochs, lr, batch_size, acc, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.845149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.876399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.931437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.892724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.892724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs     lr  batch_size       acc       auc\n",
       "0       5  0.001          16  0.903614  0.845149\n",
       "1       5  0.001          32  0.915663  0.876399\n",
       "2       5  0.001          64  0.927711  0.931437\n",
       "3       5  0.001         128  0.903614  0.892724\n",
       "4       5  0.010          16  0.903614  0.892724"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs         5.000000\n",
       "lr             0.100000\n",
       "batch_size    16.000000\n",
       "acc            0.939759\n",
       "auc            0.938899\n",
       "Name: 8, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exctract the row of best accuracy\n",
    "best_acc = df.loc[df['acc'].idxmax()]\n",
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs        10.000000\n",
       "lr             0.100000\n",
       "batch_size    16.000000\n",
       "acc            0.927711\n",
       "auc            0.955224\n",
       "Name: 20, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exctract the row of best auc\n",
    "best_auc = df.loc[df['auc'].idxmax()]\n",
    "best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DL_model_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.955224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.938899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.931437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.931437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.931437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs     lr  batch_size       acc       auc\n",
       "20      10  0.100          16  0.927711  0.955224\n",
       "8        5  0.100          16  0.939759  0.938899\n",
       "2        5  0.001          64  0.927711  0.931437\n",
       "5        5  0.010          32  0.927711  0.931437\n",
       "10       5  0.100          64  0.927711  0.931437"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the rows of best 5 auc\n",
    "best_5_auc = df.nlargest(5, 'auc')\n",
    "best_5_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
